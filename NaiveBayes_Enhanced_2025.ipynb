{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7d3afc1",
   "metadata": {},
   "source": [
    "# **Naive Bayes – Enhanced Jupyter Notebook (2025 Edition)**\n",
    "Complete, exam-ready, deeply explained Naive Bayes notebook with:\n",
    "- Theory + formulas\n",
    "- Gaussian NB from scratch\n",
    "- Multinomial NB from scratch\n",
    "- Text classification (spam filter)\n",
    "- Laplace smoothing\n",
    "- Sklearn comparisons\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4760ed77",
   "metadata": {},
   "source": [
    "## **1. Bayes' Theorem Basics**\n",
    "Bayes Theorem:\n",
    "\\[ P(y|x) = \\frac{P(x|y)P(y)}{P(x)} \\]\n",
    "Naive assumption → features independent:\n",
    "\\[ P(x|y)=\\prod_i P(x_i|y) \\]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3041997d",
   "metadata": {},
   "source": [
    "## **2. Gaussian Naive Bayes – From Scratch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30fb27a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class GaussianNB:\n",
    "    def fit(self,X,y):\n",
    "        self.classes=np.unique(y)\n",
    "        self.mean={}; self.var={}; self.priors={}\n",
    "        for c in self.classes:\n",
    "            Xc=X[y==c]\n",
    "            self.mean[c]=Xc.mean(axis=0)\n",
    "            self.var[c]=Xc.var(axis=0)+1e-9\n",
    "            self.priors[c]=Xc.shape[0]/X.shape[0]\n",
    "\n",
    "    def pdf(self,cls,x):\n",
    "        mean=self.mean[cls]; var=self.var[cls]\n",
    "        num=np.exp(-(x-mean)**2/(2*var))\n",
    "        den=np.sqrt(2*np.pi*var)\n",
    "        return num/den\n",
    "\n",
    "    def predict(self,X):\n",
    "        preds=[]\n",
    "        for x in X:\n",
    "            post=[]\n",
    "            for c in self.classes:\n",
    "                prior=np.log(self.priors[c])\n",
    "                cond=np.sum(np.log(self.pdf(c,x)))\n",
    "                post.append(prior+cond)\n",
    "            preds.append(self.classes[np.argmax(post)])\n",
    "        return np.array(preds)\n",
    "\n",
    "# Example\n",
    "np.random.seed(42)\n",
    "X=np.vstack([np.random.randn(50,2)+0, np.random.randn(50,2)+3])\n",
    "y=np.array([0]*50+[1]*50)\n",
    "model=GaussianNB(); model.fit(X,y)\n",
    "print(\"Predictions:\",model.predict(X[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253f570f",
   "metadata": {},
   "source": [
    "## **3. Multinomial Naive Bayes – For Text Classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "749b1744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [0 1 0]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "class MultinomialNB:\n",
    "    def fit(self, X, y):\n",
    "        self.classes=np.unique(y)\n",
    "        self.total_words={c:0 for c in self.classes}\n",
    "        self.word_counts={c:defaultdict(int) for c in self.classes}\n",
    "        self.priors={}\n",
    "\n",
    "        for c in self.classes:\n",
    "            Xc=X[y==c]\n",
    "            self.priors[c]=len(Xc)/len(X)\n",
    "            for row in Xc:\n",
    "                for i,count in enumerate(row):\n",
    "                    self.word_counts[c][i]+=count\n",
    "                    self.total_words[c]+=count\n",
    "\n",
    "        self.vocab_size=X.shape[1]\n",
    "\n",
    "    def predict(self, X):\n",
    "        preds=[]\n",
    "        for row in X:\n",
    "            scores={}\n",
    "            for c in self.classes:\n",
    "                log_prob=np.log(self.priors[c])\n",
    "                for i,count in enumerate(row):\n",
    "                    if count>0:\n",
    "                        num=self.word_counts[c][i]+1\n",
    "                        den=self.total_words[c]+self.vocab_size\n",
    "                        log_prob+=count*np.log(num/den)\n",
    "                scores[c]=log_prob\n",
    "            preds.append(max(scores,key=scores.get))\n",
    "        return np.array(preds)\n",
    "\n",
    "# Example tiny BOW\n",
    "X=np.array([[2,1,0],[0,1,3],[3,0,0]])\n",
    "y=np.array([0,1,0])\n",
    "mnb=MultinomialNB(); mnb.fit(X,y)\n",
    "print(\"Prediction:\", mnb.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d76ef18",
   "metadata": {},
   "source": [
    "## **4. Simple Spam Filter (Multinomial NB)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcfb5224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [1 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "docs=[\"win money now\",\"free prize win\",\"meeting at office\",\"project discussion\"]\n",
    "labels=np.array([1,1,0,0])\n",
    "\n",
    "cv=CountVectorizer()\n",
    "X=cv.fit_transform(docs).toarray()\n",
    "\n",
    "mnb=MultinomialNB()\n",
    "mnb.fit(X,labels)\n",
    "\n",
    "test=[\"win free money\",\"office meeting now\"]\n",
    "Xt=cv.transform(test).toarray()\n",
    "print(\"Predictions:\", mnb.predict(Xt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505f5142",
   "metadata": {},
   "source": [
    "## **5. Compare GaussianNB With sklearn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e168e8b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [4, 3]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnaive_bayes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GaussianNB \u001b[38;5;28;01mas\u001b[39;00m SkGNB\n\u001b[32m      3\u001b[39m sk=SkGNB()\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43msk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSklearn Pred:\u001b[39m\u001b[33m\"\u001b[39m,sk.predict(X[:\u001b[32m5\u001b[39m]))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ishan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ishan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\naive_bayes.py:266\u001b[39m, in \u001b[36mGaussianNB.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    243\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Fit Gaussian Naive Bayes according to X, y.\u001b[39;00m\n\u001b[32m    244\u001b[39m \n\u001b[32m    245\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    263\u001b[39m \u001b[33;03m    Returns the instance itself.\u001b[39;00m\n\u001b[32m    264\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    265\u001b[39m y = validate_data(\u001b[38;5;28mself\u001b[39m, y=y)\n\u001b[32m--> \u001b[39m\u001b[32m266\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_partial_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_refit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ishan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\naive_bayes.py:426\u001b[39m, in \u001b[36mGaussianNB._partial_fit\u001b[39m\u001b[34m(self, X, y, classes, _refit, sample_weight)\u001b[39m\n\u001b[32m    423\u001b[39m     \u001b[38;5;28mself\u001b[39m.classes_ = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    425\u001b[39m first_call = _check_partial_fit_first_call(\u001b[38;5;28mself\u001b[39m, classes)\n\u001b[32m--> \u001b[39m\u001b[32m426\u001b[39m X, y = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfirst_call\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    427\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    428\u001b[39m     sample_weight = _check_sample_weight(sample_weight, X)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ishan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2971\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2969\u001b[39m         y = check_array(y, input_name=\u001b[33m\"\u001b[39m\u001b[33my\u001b[39m\u001b[33m\"\u001b[39m, **check_y_params)\n\u001b[32m   2970\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2971\u001b[39m         X, y = \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2972\u001b[39m     out = X, y\n\u001b[32m   2974\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params.get(\u001b[33m\"\u001b[39m\u001b[33mensure_2d\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ishan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1387\u001b[39m, in \u001b[36mcheck_X_y\u001b[39m\u001b[34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[39m\n\u001b[32m   1368\u001b[39m X = check_array(\n\u001b[32m   1369\u001b[39m     X,\n\u001b[32m   1370\u001b[39m     accept_sparse=accept_sparse,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1382\u001b[39m     input_name=\u001b[33m\"\u001b[39m\u001b[33mX\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1383\u001b[39m )\n\u001b[32m   1385\u001b[39m y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric, estimator=estimator)\n\u001b[32m-> \u001b[39m\u001b[32m1387\u001b[39m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1389\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ishan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:473\u001b[39m, in \u001b[36mcheck_consistent_length\u001b[39m\u001b[34m(*arrays)\u001b[39m\n\u001b[32m    471\u001b[39m lengths = [_num_samples(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m arrays \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[32m    472\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(lengths)) > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m473\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    474\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    475\u001b[39m         % [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[32m    476\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Found input variables with inconsistent numbers of samples: [4, 3]"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB as SkGNB\n",
    "\n",
    "sk=SkGNB()\n",
    "sk.fit(X,y)\n",
    "print(\"Sklearn Pred:\",sk.predict(X[:5]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2c6ad6",
   "metadata": {},
   "source": [
    "## **6. Summary**\n",
    "- Gaussian NB: numeric features\n",
    "- Multinomial NB: text BOW\n",
    "- Laplace smoothing\n",
    "- Log-probability to avoid underflow\n",
    "- Fast + effective for many tasks\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
